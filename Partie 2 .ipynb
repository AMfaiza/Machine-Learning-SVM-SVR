{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aca6a51",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebc5d9",
   "metadata": {},
   "source": [
    "• Importation dela fonction load_diabetes du module sklearn.datasets pour charger la base de données \"Diabetes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77431bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Chargement de la base de données Diabetes\n",
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data  # Caractéristiques (variables indépendantes)\n",
    "y = diabetes_data.target  # Variable cible (progression de la maladie)\n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3d69d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbca9e",
   "metadata": {},
   "source": [
    "• On utilisé la fonction train_test_split du module sklearn.model_selection pour effectuer une partition aléatoire des données en ensembles d'apprentissage et de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a838a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'apprentissage : 309\n",
      "Taille de l'ensemble de test : 133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partition aléatoire en partie apprentissage et partie test (70% apprentissage, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Affichage de la taille des ensembles d'apprentissage et de test\n",
    "print(\"Taille de l'ensemble d'apprentissage :\", len(X_train))\n",
    "print(\"Taille de l'ensemble de test :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185fbe4",
   "metadata": {},
   "source": [
    "###### Le paramètre test_size est fixé à 0.3, ce qui signifie que 30% des données seront utilisées pour le test, et le paramètre random_state est utilisé pour garantir la reproductibilité des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef99d8",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5976af5",
   "metadata": {},
   "source": [
    "• On normalise les données à l'aide d'un objet StandardScaler pour rendre les caractéristiques comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36df5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a9851",
   "metadata": {},
   "source": [
    "• On construit notre modèle SVM de régression avec le noyau RBF en utilisant la classe SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0bcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Construction du modèle\n",
    "svm_regressor = SVR(kernel='rbf')\n",
    "svm_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = svm_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e14be",
   "metadata": {},
   "source": [
    "• ON Calcule l'erreur quadratique moyenne à l'aide de la fonction mean_squared_error du module sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d49022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne sur l'ensemble de test : 4528.172807417007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Affichage de l'erreur quadratique moyenne\n",
    "print(\"Erreur quadratique moyenne sur l'ensemble de test :\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830596df",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce866e",
   "metadata": {},
   "source": [
    "• Détermination le meilleur noyau à utiliser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478e8f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'kernel': 'linear'}\n",
      "Meilleure erreur quadratique moyenne (validation croisée) : 3245.3537352399217\n",
      "Erreur quadratique moyenne sur l'ensemble de test avec le meilleur modèle : 2856.7581589130787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir la grille des paramètres à rechercher\n",
    "param_grid = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Construire le modèle SVM de régression\n",
    "svm_regressor = SVR()\n",
    "\n",
    "# Utiliser GridSearchCV pour la recherche sur la grille\n",
    "grid_search = GridSearchCV(svm_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres et la meilleure performance\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleure erreur quadratique moyenne (validation croisée) :\", -grid_search.best_score_)\n",
    "\n",
    "# Utiliser le meilleur modèle pour faire des prédictions sur l'ensemble de test\n",
    "best_svm_regressor = grid_search.best_estimator_\n",
    "y_pred_best = best_svm_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne sur l'ensemble de test avec le meilleur modèle\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "print(\"Erreur quadratique moyenne sur l'ensemble de test avec le meilleur modèle :\", mse_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31d7e6",
   "metadata": {},
   "source": [
    "######  Le modèle SVM de régression avec un noyau linéaire semble donner de meilleures performances sur l'ensemble de données par rapport aux autres noyaux considérés dans la recherche sur la grille."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc85cf2",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91ad99",
   "metadata": {},
   "source": [
    "1. Arbre de régression avec la méthode CART :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a05423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne avec l'arbre CART sur l'ensemble de test : 5686.601503759399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "cart_regressor = DecisionTreeRegressor(random_state=42)\n",
    "cart_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred_cart = cart_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne avec l'arbre CART\n",
    "mse_cart = mean_squared_error(y_test, y_pred_cart)\n",
    "print(\"Erreur quadratique moyenne avec l'arbre CART sur l'ensemble de test :\", mse_cart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb66f3",
   "metadata": {},
   "source": [
    "2. Random Forest :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742d1d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne avec la forêt aléatoire sur l'ensemble de test : 2863.26317518797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_regressor = RandomForestRegressor(random_state=42)\n",
    "random_forest_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred_rf = random_forest_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne avec la forêt aléatoire\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Erreur quadratique moyenne avec la forêt aléatoire sur l'ensemble de test :\", mse_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0a10e",
   "metadata": {},
   "source": [
    "###### On peut observer que Random Forest offre de meilleures performances de prédiction que l'arbre CART."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3b06e",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e50e68",
   "metadata": {},
   "source": [
    "### Pour comparer les résultats des trois méthodes SVM avec noyau linéaire, Random Forest et arbre CART, on examine les aspects suivants: temps CPU, le nombre d'itérations, ainsi que les performances des modèles en termes de métriques comme le MSE (Mean Squared Error) et le coefficient de détermination (R²). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8336900",
   "metadata": {},
   "source": [
    "• On met en place une fonction evaluate_model évaluer les performances d'un modèle en termes de MSE, R², temps CPU et nombre d'itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a3c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "# Fonction pour évaluer les performances d'un modèle\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'cpu_time': end_time - start_time,\n",
    "        'iterations': getattr(model, 'n_iter_', None)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ad79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour le modèle SVM (noyau linéaire): {'mse': 2856.7581589130787, 'r2': 0.4708048735044591, 'cpu_time': 0.003992795944213867, 'iterations': None}\n",
      "Résultats pour le modèle Random Forest: {'mse': 2863.26317518797, 'r2': 0.4695998632379421, 'cpu_time': 0.019987821578979492, 'iterations': None}\n",
      "Résultats pour le modèle arbre CART: {'mse': 5686.601503759399, 'r2': -0.053404465730713335, 'cpu_time': 0.0010175704956054688, 'iterations': None}\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle SVM avec noyau linéaire\n",
    "svm_results = evaluate_model(best_svm_regressor, X_test_scaled, y_test)\n",
    "\n",
    "# Évaluation du modèle Random Forest\n",
    "rf_results = evaluate_model(random_forest_regressor, X_test_scaled, y_test)\n",
    "\n",
    "# Évaluation du modèle arbre CART\n",
    "cart_results = evaluate_model(cart_regressor, X_test_scaled, y_test)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Résultats pour le modèle SVM (noyau linéaire):\", svm_results)\n",
    "print(\"Résultats pour le modèle Random Forest:\", rf_results)\n",
    "print(\"Résultats pour le modèle arbre CART:\", cart_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb2154",
   "metadata": {},
   "source": [
    "On observe que :\n",
    "\n",
    "•Le modèle SVM avec noyau linéaire semble donner de meilleures performances en termes de MSE et R² par rapport à l'arbre CART.\n",
    "\n",
    "•Random Forest offre des performances similaires à celles du SVM, mais avec un temps CPU légèrement plus élevé.\n",
    "\n",
    "•L'arbre CART a une performance beaucoup plus faible en termes de MSE et R², mais il s'exécute très rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148a707",
   "metadata": {},
   "source": [
    "###### En fonction de ces observations, le modèle SVM avec noyau linéaire semble être une option solide, basé sur MSE et R²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ed191",
   "metadata": {},
   "source": [
    "# MERCI !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
